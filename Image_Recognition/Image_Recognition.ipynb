{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"H100","authorship_tag":"ABX9TyMfAx9gK7COFuT7kS8rZORh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3VAlXBWYxwi"},"outputs":[],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Define your Google Drive path\n","base_path = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/image_recognition_project'\n","\n","# Create folder structure\n","folders = [\n","    'dataset/sample_100',\n","    'dataset/full_collection',\n","    'reference_faces',\n","    'output/matched',\n","    'output/not_matched',\n","    'output/review',\n","    'logs'\n","]\n","\n","print(\"Creating folder structure...\")\n","print(\"=\"*70)\n","\n","for folder in folders:\n","    folder_path = os.path.join(base_path, folder)\n","    os.makedirs(folder_path, exist_ok=True)\n","    print(f\"‚úì Created: {folder}\")\n","\n","print(\"=\"*70)\n","print(\"‚úÖ Folder structure created successfully!\")\n","print(\"\\nüìÇ Your project structure:\")\n","print(f\"\\n{base_path}/\")\n","print(\"‚îú‚îÄ‚îÄ dataset/\")\n","print(\"‚îÇ   ‚îú‚îÄ‚îÄ sample_100/           ‚Üê Upload 100 test photos here\")\n","print(\"‚îÇ   ‚îî‚îÄ‚îÄ full_collection/      ‚Üê Upload all 5K photos here (later)\")\n","print(\"‚îú‚îÄ‚îÄ reference_faces/          ‚Üê Upload 5-10 photos of YOURSELF here\")\n","print(\"‚îú‚îÄ‚îÄ output/\")\n","print(\"‚îÇ   ‚îú‚îÄ‚îÄ matched/              ‚Üê Photos with you (auto-generated)\")\n","print(\"‚îÇ   ‚îú‚îÄ‚îÄ not_matched/          ‚Üê Photos without you (auto-generated)\")\n","print(\"‚îÇ   ‚îî‚îÄ‚îÄ review/               ‚Üê Borderline cases (auto-generated)\")\n","print(\"‚îî‚îÄ‚îÄ logs/                     ‚Üê Processing logs (auto-generated)\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìå NEXT STEPS:\")\n","print(\"=\"*70)\n","print(\"1. Go to your Google Drive\")\n","print(f\"2. Navigate to: Colab Notebooks/Deep Learning/image_recognition_project\")\n","print(\"3. Upload files to these folders:\")\n","print(\"   ‚Ä¢ reference_faces/ ‚Üí 5-10 clear photos of YOUR face\")\n","print(\"   ‚Ä¢ dataset/sample_100/ ‚Üí 100 diverse test photos\")\n","print(\"\\n4. After uploading, come back to Colab and continue with the code\")\n","print(\"=\"*70)"],"metadata":{"id":"oLoCzOtKZkIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_folder_structure(base_path):\n","    \"\"\"\n","    Check and display the folder structure and file counts\n","    \"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"üìÅ FOLDER STRUCTURE VERIFICATION\")\n","    print(\"=\"*70)\n","\n","    # Check reference faces\n","    ref_folder = os.path.join(base_path, 'reference_faces')\n","    ref_files = [f for f in os.listdir(ref_folder)\n","                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    print(f\"\\nüì∏ Reference Faces: {ref_folder}\")\n","    print(f\"   Files found: {len(ref_files)}\")\n","    if len(ref_files) > 0:\n","        print(\"   Sample files:\")\n","        for f in ref_files[:5]:\n","            print(f\"      ‚Ä¢ {f}\")\n","    else:\n","        print(\"   ‚ö†Ô∏è WARNING: No reference photos found!\")\n","\n","    # Check sample dataset\n","    sample_folder = os.path.join(base_path, 'dataset/sample_100')\n","    sample_files = [f for f in os.listdir(sample_folder)\n","                    if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    print(f\"\\nüì∑ Sample Dataset: {sample_folder}\")\n","    print(f\"   Files found: {len(sample_files)}\")\n","    if len(sample_files) > 0:\n","        print(\"   Sample files:\")\n","        for f in sample_files[:5]:\n","            print(f\"      ‚Ä¢ {f}\")\n","        if len(sample_files) > 5:\n","            print(f\"      ... and {len(sample_files) - 5} more\")\n","    else:\n","        print(\"   ‚ö†Ô∏è WARNING: No test photos found!\")\n","\n","    # Check output folders\n","    output_folders = ['matched', 'not_matched', 'review']\n","    print(f\"\\nüìÇ Output Folders:\")\n","    for folder in output_folders:\n","        folder_path = os.path.join(base_path, 'output', folder)\n","        if os.path.exists(folder_path):\n","            print(f\"   ‚úì {folder}/\")\n","        else:\n","            print(f\"   ‚úó {folder}/ (missing)\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","\n","    # Summary\n","    if len(ref_files) > 0 and len(sample_files) > 0:\n","        print(\"‚úÖ STATUS: Ready to proceed with processing!\")\n","        print(f\"   ‚Ä¢ Reference faces: {len(ref_files)} photos\")\n","        print(f\"   ‚Ä¢ Test dataset: {len(sample_files)} photos\")\n","    else:\n","        print(\"‚ö†Ô∏è STATUS: Please upload files before proceeding\")\n","        if len(ref_files) == 0:\n","            print(\"   ‚Ä¢ Missing: Reference photos of yourself\")\n","        if len(sample_files) == 0:\n","            print(\"   ‚Ä¢ Missing: Test photos in sample_100\")\n","\n","    print(\"=\"*70)\n","\n","    return len(ref_files), len(sample_files)\n","\n","# Run verification\n","base_path = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/image_recognition_project'\n","num_ref, num_sample = check_folder_structure(base_path)"],"metadata":{"id":"KhKTzhLNhq-0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install face_recognition library\n","print(\"Installing required libraries...\")\n","print(\"=\"*70)\n","\n","!pip install -q face_recognition\n","\n","print(\"\\n‚úÖ Installation complete!\")\n","print(\"=\"*70)"],"metadata":{"id":"vk17GWxiiVSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import all necessary libraries\n","import face_recognition\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import pandas as pd\n","from tqdm import tqdm\n","import json\n","import os\n","import shutil\n","\n","print(\"‚úÖ All libraries imported successfully!\")"],"metadata":{"id":"ugzAueZJidYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_reference_faces(reference_folder):\n","    \"\"\"\n","    Load reference images and create face encodings\n","\n","    Returns:\n","        reference_encodings: List of face encodings from reference images\n","        reference_names: List of filenames for tracking\n","    \"\"\"\n","    reference_encodings = []\n","    reference_names = []\n","\n","    # Get all image files from reference folder\n","    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n","    reference_files = [f for f in os.listdir(reference_folder)\n","                      if any(f.endswith(ext) for ext in image_extensions)]\n","\n","    if len(reference_files) == 0:\n","        print(\"‚ö†Ô∏è No reference images found!\")\n","        return [], []\n","\n","    print(\"=\"*70)\n","    print(f\"LOADING REFERENCE FACES\")\n","    print(\"=\"*70)\n","    print(f\"Processing {len(reference_files)} reference images...\\n\")\n","\n","    for filename in reference_files:\n","        file_path = os.path.join(reference_folder, filename)\n","\n","        try:\n","            # Load image\n","            image = face_recognition.load_image_file(file_path)\n","\n","            # Get face encodings\n","            encodings = face_recognition.face_encodings(image)\n","\n","            if len(encodings) > 0:\n","                # Use the first face found\n","                reference_encodings.append(encodings[0])\n","                reference_names.append(filename)\n","                print(f\"  ‚úì {filename}: Face encoded successfully\")\n","            else:\n","                print(f\"  ‚úó {filename}: No face detected\")\n","\n","        except Exception as e:\n","            print(f\"  ‚úó {filename}: Error - {str(e)}\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(f\"‚úÖ Successfully encoded {len(reference_encodings)} reference faces\")\n","    print(f\"   Each encoding has {len(reference_encodings[0])} dimensions\")\n","    print(\"=\"*70 + \"\\n\")\n","\n","    return reference_encodings, reference_names\n","\n","\n","# Load your reference faces\n","base_path = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/image_recognition_project'\n","reference_folder = os.path.join(base_path, 'reference_faces')\n","reference_encodings, reference_names = load_reference_faces(reference_folder)"],"metadata":{"id":"8nnZ_I7Ligt0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_reference_faces(reference_folder, reference_names):\n","    \"\"\"\n","    Display all reference faces to verify they loaded correctly\n","    \"\"\"\n","    num_images = len(reference_names)\n","\n","    if num_images == 0:\n","        print(\"No reference images to display\")\n","        return\n","\n","    # Calculate grid size\n","    cols = min(5, num_images)\n","    rows = (num_images + cols - 1) // cols\n","\n","    fig, axes = plt.subplots(rows, cols, figsize=(15, 3*rows))\n","\n","    # Flatten axes array for easier indexing\n","    if num_images == 1:\n","        axes = [axes]\n","    else:\n","        axes = axes.flatten() if num_images > cols else axes\n","\n","    for idx, filename in enumerate(reference_names):\n","        file_path = os.path.join(reference_folder, filename)\n","        img = Image.open(file_path)\n","        axes[idx].imshow(img)\n","        axes[idx].set_title(filename, fontsize=10)\n","        axes[idx].axis('off')\n","\n","    # Hide extra subplots if any\n","    for idx in range(num_images, len(axes) if isinstance(axes, np.ndarray) else 1):\n","        if isinstance(axes, np.ndarray):\n","            axes[idx].axis('off')\n","\n","    plt.suptitle(\"‚úÖ Your Reference Faces (These will be used for matching)\",\n","                 fontsize=14, fontweight='bold')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Visualize your reference faces\n","visualize_reference_faces(reference_folder, reference_names)"],"metadata":{"id":"D1GSzlpmjxYL","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_single_image(image_path, reference_encodings, tolerance=0.6):\n","    \"\"\"\n","    Process a single image and determine if it contains the reference person\n","\n","    Args:\n","        image_path: Path to the image file\n","        reference_encodings: List of reference face encodings\n","        tolerance: Distance threshold (lower = more strict)\n","\n","    Returns:\n","        dict with results\n","    \"\"\"\n","    result = {\n","        'filename': os.path.basename(image_path),\n","        'faces_detected': 0,\n","        'min_distance': None,\n","        'is_match': False,\n","        'classification': 'error',\n","        'error': None\n","    }\n","\n","    try:\n","        # Load image\n","        image = face_recognition.load_image_file(image_path)\n","\n","        # Detect faces and get encodings\n","        face_locations = face_recognition.face_locations(image)\n","        face_encodings = face_recognition.face_encodings(image, face_locations)\n","\n","        result['faces_detected'] = len(face_encodings)\n","\n","        if len(face_encodings) == 0:\n","            result['classification'] = 'not_matched'  # No faces = not matched\n","            return result\n","\n","        # Compare each detected face with reference faces\n","        all_distances = []\n","\n","        for face_encoding in face_encodings:\n","            # Calculate distance to each reference encoding\n","            distances = face_recognition.face_distance(reference_encodings, face_encoding)\n","            min_dist = np.min(distances)\n","            all_distances.append(min_dist)\n","\n","        # Get the minimum distance across all faces in the image\n","        result['min_distance'] = float(np.min(all_distances))\n","\n","        # Classify based on threshold\n","        if result['min_distance'] < tolerance:\n","            result['is_match'] = True\n","            result['classification'] = 'matched'\n","        elif result['min_distance'] < tolerance + 0.1:  # Borderline cases\n","            result['classification'] = 'review'\n","        else:\n","            result['classification'] = 'not_matched'\n","\n","    except Exception as e:\n","        result['error'] = str(e)\n","        result['classification'] = 'error'\n","\n","    return result\n","\n","\n","def process_dataset(input_folder, output_base_folder, reference_encodings,\n","                   tolerance=0.6, copy_files=True):\n","    \"\"\"\n","    Process all images in a folder\n","\n","    Args:\n","        input_folder: Folder containing images to process\n","        output_base_folder: Base folder for outputs\n","        reference_encodings: Reference face encodings\n","        tolerance: Matching threshold\n","        copy_files: Whether to copy files to output folders\n","\n","    Returns:\n","        DataFrame with all results\n","    \"\"\"\n","    # Get all image files\n","    image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG', '.heic', '.HEIC']\n","    image_files = [f for f in os.listdir(input_folder)\n","                   if any(f.endswith(ext) for ext in image_extensions)]\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"STARTING IMAGE PROCESSING\")\n","    print(\"=\"*70)\n","    print(f\"üìÅ Input folder: {input_folder}\")\n","    print(f\"üìä Found {len(image_files)} images to process\")\n","    print(f\"üéØ Tolerance: {tolerance}\")\n","    print(f\"üë§ Reference faces: {len(reference_encodings)}\")\n","    print(\"=\"*70 + \"\\n\")\n","\n","    if len(image_files) == 0:\n","        print(\"‚ö†Ô∏è No images found in input folder!\")\n","        return pd.DataFrame()\n","\n","    # Process each image\n","    results = []\n","\n","    for filename in tqdm(image_files, desc=\"Processing images\", unit=\"image\"):\n","        image_path = os.path.join(input_folder, filename)\n","\n","        # Process the image\n","        result = process_single_image(image_path, reference_encodings, tolerance)\n","        result['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","        results.append(result)\n","\n","        # Copy file to appropriate folder\n","        if copy_files:\n","            classification = result['classification']\n","            dest_folder = os.path.join(output_base_folder, classification)\n","            dest_path = os.path.join(dest_folder, filename)\n","\n","            try:\n","                shutil.copy2(image_path, dest_path)\n","            except Exception as e:\n","                print(f\"\\n‚ö†Ô∏è Error copying {filename}: {e}\")\n","\n","    # Create DataFrame\n","    results_df = pd.DataFrame(results)\n","\n","    return results_df"],"metadata":{"id":"XAmEOqy8kFXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define paths\n","base_path = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/image_recognition_project'\n","input_folder = os.path.join(base_path, 'dataset/sample_100')\n","output_folder = os.path.join(base_path, 'output')\n","\n","# Set tolerance\n","# Lower = more strict (fewer false positives, might miss some photos of you)\n","# Higher = more lenient (catches more photos of you, might have false positives)\n","# Recommended range: 0.4 to 0.6\n","tolerance = 0.6\n","\n","print(\"‚öôÔ∏è CONFIGURATION:\")\n","print(\"=\"*70)\n","print(f\"Tolerance: {tolerance}\")\n","print(f\"Reference faces loaded: {len(reference_encodings)}\")\n","print(f\"Input folder: {input_folder}\")\n","print(f\"Output folder: {output_folder}\")\n","print(\"=\"*70)\n","\n","# Process all images\n","results_df = process_dataset(\n","    input_folder=input_folder,\n","    output_base_folder=output_folder,\n","    reference_encodings=reference_encodings,\n","    tolerance=tolerance,\n","    copy_files=True\n",")"],"metadata":{"id":"Zzl0EF0fk0k9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_results(results_df, tolerance):\n","    \"\"\"Display comprehensive analysis of results\"\"\"\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"üìä PROCESSING RESULTS - SUMMARY\")\n","    print(\"=\"*70)\n","\n","    print(f\"\\nüî¢ Total Statistics:\")\n","    print(f\"   ‚Ä¢ Total images processed: {len(results_df)}\")\n","    print(f\"   ‚Ä¢ Tolerance used: {tolerance}\")\n","\n","    print(f\"\\nüìã Classification Breakdown:\")\n","    classification_counts = results_df['classification'].value_counts()\n","    for classification, count in classification_counts.items():\n","        percentage = (count / len(results_df)) * 100\n","        emoji = \"‚úÖ\" if classification == \"matched\" else \"‚ùå\" if classification == \"not_matched\" else \"‚ö†Ô∏è\" if classification == \"review\" else \"üî¥\"\n","        print(f\"   {emoji} {classification.upper()}: {count} ({percentage:.1f}%)\")\n","\n","    print(f\"\\nüë§ Face Detection:\")\n","    print(f\"   ‚Ä¢ Images with faces detected: {len(results_df[results_df['faces_detected'] > 0])}\")\n","    print(f\"   ‚Ä¢ Images without faces: {len(results_df[results_df['faces_detected'] == 0])}\")\n","    print(f\"   ‚Ä¢ Total faces detected: {results_df['faces_detected'].sum()}\")\n","\n","    # Distance statistics (only for images with faces)\n","    matched_df = results_df[results_df['min_distance'].notna()]\n","    if len(matched_df) > 0:\n","        print(f\"\\nüìè Distance Statistics (lower = more similar):\")\n","        print(f\"   ‚Ä¢ Mean distance: {matched_df['min_distance'].mean():.4f}\")\n","        print(f\"   ‚Ä¢ Min distance: {matched_df['min_distance'].min():.4f}\")\n","        print(f\"   ‚Ä¢ Max distance: {matched_df['min_distance'].max():.4f}\")\n","        print(f\"   ‚Ä¢ Median distance: {matched_df['min_distance'].median():.4f}\")\n","\n","        # Show distance ranges\n","        matched_count = len(matched_df[matched_df['classification'] == 'matched'])\n","        review_count = len(matched_df[matched_df['classification'] == 'review'])\n","        not_matched_count = len(matched_df[matched_df['classification'] == 'not_matched'])\n","\n","        print(f\"\\nüìä Distance Ranges:\")\n","        if matched_count > 0:\n","            matched_distances = matched_df[matched_df['classification'] == 'matched']['min_distance']\n","            print(f\"   ‚Ä¢ MATCHED (< {tolerance}): {matched_distances.min():.4f} to {matched_distances.max():.4f}\")\n","        if review_count > 0:\n","            review_distances = matched_df[matched_df['classification'] == 'review']['min_distance']\n","            print(f\"   ‚Ä¢ REVIEW ({tolerance} to {tolerance+0.1}): {review_distances.min():.4f} to {review_distances.max():.4f}\")\n","        if not_matched_count > 0:\n","            not_matched_distances = matched_df[matched_df['classification'] == 'not_matched']['min_distance']\n","            print(f\"   ‚Ä¢ NOT MATCHED (‚â• {tolerance+0.1}): {not_matched_distances.min():.4f} to {not_matched_distances.max():.4f}\")\n","\n","    # Errors\n","    errors = results_df[results_df['classification'] == 'error']\n","    if len(errors) > 0:\n","        print(f\"\\n‚ö†Ô∏è Errors Encountered: {len(errors)}\")\n","        print(\"\\nError Details:\")\n","        for idx, row in errors.iterrows():\n","            print(f\"   ‚Ä¢ {row['filename']}: {row['error']}\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"‚úÖ ANALYSIS COMPLETE\")\n","    print(\"=\"*70)\n","\n","# Run analysis\n","analyze_results(results_df, tolerance)"],"metadata":{"id":"T-U-zRDmk2_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_distance_distribution(results_df, tolerance):\n","    \"\"\"Plot distance distribution and classification breakdown\"\"\"\n","\n","    matched_df = results_df[results_df['min_distance'].notna()]\n","\n","    if len(matched_df) == 0:\n","        print(\"‚ö†Ô∏è No faces detected in any images!\")\n","        return\n","\n","    fig = plt.figure(figsize=(16, 5))\n","\n","    # 1. Histogram of distances\n","    plt.subplot(1, 3, 1)\n","    plt.hist(matched_df['min_distance'], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n","    plt.axvline(tolerance, color='red', linestyle='--', linewidth=2,\n","                label=f'Threshold: {tolerance}')\n","    plt.axvline(tolerance + 0.1, color='orange', linestyle='--', linewidth=2,\n","                label=f'Review boundary: {tolerance + 0.1}')\n","    plt.xlabel('Distance', fontsize=12)\n","    plt.ylabel('Frequency', fontsize=12)\n","    plt.title('Distribution of Face Distances', fontsize=14, fontweight='bold')\n","    plt.legend()\n","    plt.grid(True, alpha=0.3)\n","\n","    # 2. Box plot by classification\n","    plt.subplot(1, 3, 2)\n","    classifications = ['matched', 'review', 'not_matched']\n","    data_to_plot = []\n","    labels_to_plot = []\n","\n","    for c in classifications:\n","        if c in matched_df['classification'].values:\n","            data_to_plot.append(matched_df[matched_df['classification'] == c]['min_distance'].values)\n","            labels_to_plot.append(c)\n","\n","    if data_to_plot:\n","        bp = plt.boxplot(data_to_plot, labels=labels_to_plot, patch_artist=True)\n","        colors = ['lightgreen', 'yellow', 'lightcoral']\n","        for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n","            patch.set_facecolor(color)\n","\n","        plt.axhline(tolerance, color='red', linestyle='--', linewidth=2,\n","                   label=f'Threshold: {tolerance}')\n","        plt.ylabel('Distance', fontsize=12)\n","        plt.title('Distance by Classification', fontsize=14, fontweight='bold')\n","        plt.legend()\n","        plt.grid(True, alpha=0.3, axis='y')\n","\n","    # 3. Pie chart of classifications\n","    plt.subplot(1, 3, 3)\n","    classification_counts = results_df['classification'].value_counts()\n","    colors_pie = {'matched': 'lightgreen', 'review': 'yellow',\n","                  'not_matched': 'lightcoral', 'error': 'gray'}\n","    colors_list = [colors_pie.get(label, 'lightgray') for label in classification_counts.index]\n","\n","    plt.pie(classification_counts.values, labels=classification_counts.index,\n","            autopct='%1.1f%%', startangle=90, colors=colors_list)\n","    plt.title('Classification Distribution', fontsize=14, fontweight='bold')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Visualize results\n","visualize_distance_distribution(results_df, tolerance)"],"metadata":{"id":"4XCN14NQnN6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_sample_results(results_df, output_folder, classification='matched', num_samples=6):\n","    \"\"\"\n","    Display sample images from a specific classification\n","    \"\"\"\n","    samples = results_df[results_df['classification'] == classification].head(num_samples)\n","\n","    if len(samples) == 0:\n","        print(f\"‚ÑπÔ∏è No images in '{classification}' category\")\n","        return\n","\n","    num_images = len(samples)\n","    cols = min(3, num_images)\n","    rows = (num_images + cols - 1) // cols\n","\n","    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n","\n","    if num_images == 1:\n","        axes = [axes]\n","    else:\n","        axes = axes.flatten()\n","\n","    for idx, (_, row) in enumerate(samples.iterrows()):\n","        img_path = os.path.join(output_folder, classification, row['filename'])\n","\n","        if os.path.exists(img_path):\n","            img = Image.open(img_path)\n","            axes[idx].imshow(img)\n","\n","            # Create title with info\n","            if row['min_distance']:\n","                title = f\"{row['filename']}\\nDistance: {row['min_distance']:.3f} | Faces: {row['faces_detected']}\"\n","            else:\n","                title = f\"{row['filename']}\\nNo faces detected\"\n","\n","            axes[idx].set_title(title, fontsize=9)\n","            axes[idx].axis('off')\n","\n","    # Hide extra subplots\n","    for idx in range(num_images, len(axes)):\n","        axes[idx].axis('off')\n","\n","    emoji = \"‚úÖ\" if classification == \"matched\" else \"‚ùå\" if classification == \"not_matched\" else \"‚ö†Ô∏è\"\n","    plt.suptitle(f\"{emoji} Sample {classification.upper()} Images\",\n","                 fontsize=16, fontweight='bold')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Show matched images\n","print(\"üì∏ SAMPLE MATCHED IMAGES (Photos containing YOU):\")\n","print(\"=\"*70)\n","show_sample_results(results_df, output_folder, 'matched', num_samples=6)\n","\n","print(\"\\nüì∏ SAMPLE NOT MATCHED IMAGES (Photos without you):\")\n","print(\"=\"*70)\n","show_sample_results(results_df, output_folder, 'not_matched', num_samples=6)\n","\n","if len(results_df[results_df['classification'] == 'review']) > 0:\n","    print(\"\\nüì∏ SAMPLE REVIEW IMAGES (Borderline cases - please check manually):\")\n","    print(\"=\"*70)\n","    show_sample_results(results_df, output_folder, 'review', num_samples=6)"],"metadata":{"id":"IJ4DXhSgnWRU","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_results(results_df, base_path, tolerance, num_references):\n","    \"\"\"Save results to CSV and JSON\"\"\"\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"üíæ SAVING RESULTS\")\n","    print(\"=\"*70)\n","\n","    # Save detailed results CSV\n","    results_csv_path = os.path.join(base_path, 'logs', 'results.csv')\n","    results_df.to_csv(results_csv_path, index=False)\n","    print(f\"‚úì Detailed results saved to: results.csv\")\n","\n","    # Save summary JSON\n","    summary = {\n","        'total_images': len(results_df),\n","        'classification_counts': results_df['classification'].value_counts().to_dict(),\n","        'faces_detected_total': int(results_df['faces_detected'].sum()),\n","        'images_with_faces': len(results_df[results_df['faces_detected'] > 0]),\n","        'tolerance_used': tolerance,\n","        'reference_faces_count': num_references,\n","        'processing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        'distance_statistics': {\n","            'mean': float(results_df[results_df['min_distance'].notna()]['min_distance'].mean()) if len(results_df[results_df['min_distance'].notna()]) > 0 else None,\n","            'min': float(results_df[results_df['min_distance'].notna()]['min_distance'].min()) if len(results_df[results_df['min_distance'].notna()]) > 0 else None,\n","            'max': float(results_df[results_df['min_distance'].notna()]['min_distance'].max()) if len(results_df[results_df['min_distance'].notna()]) > 0 else None,\n","        }\n","    }\n","\n","    summary_path = os.path.join(base_path, 'logs', 'summary.json')\n","    with open(summary_path, 'w') as f:\n","        json.dump(summary, f, indent=2)\n","    print(f\"‚úì Summary saved to: summary.json\")\n","\n","    print(\"\\nüìÇ All results saved in:\")\n","    print(f\"   {os.path.join(base_path, 'logs')}/\")\n","    print(\"=\"*70)\n","\n","# Save results\n","save_results(results_df, base_path, tolerance, len(reference_encodings))"],"metadata":{"id":"wPMouhEgnjyo","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*70)\n","print(\"üìã SAMPLE RESULTS TABLE\")\n","print(\"=\"*70)\n","print(\"\\nFirst 10 results:\")\n","display(results_df.head(10))\n","\n","print(\"\\nLast 10 results:\")\n","display(results_df.tail(10))"],"metadata":{"id":"CbZif7ignqQm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\n\" + \"=\"*70)\n","print(\"üéâ PROCESSING COMPLETE!\")\n","print(\"=\"*70)\n","\n","print(f\"\\nüìä Final Summary:\")\n","print(f\"   ‚Ä¢ Total images processed: {len(results_df)}\")\n","print(f\"   ‚Ä¢ Matched (contain you): {len(results_df[results_df['classification'] == 'matched'])}\")\n","print(f\"   ‚Ä¢ Not matched: {len(results_df[results_df['classification'] == 'not_matched'])}\")\n","print(f\"   ‚Ä¢ Review needed: {len(results_df[results_df['classification'] == 'review'])}\")\n","print(f\"   ‚Ä¢ Errors: {len(results_df[results_df['classification'] == 'error'])}\")\n","\n","print(f\"\\nüìÅ Check your results in Google Drive:\")\n","print(f\"   Colab Notebooks/Deep Learning/image_recognition_project/output/\")\n","print(f\"   ‚Ä¢ matched/ - Photos containing you\")\n","print(f\"   ‚Ä¢ not_matched/ - Photos without you\")\n","print(f\"   ‚Ä¢ review/ - Borderline cases (check manually)\")\n","\n","print(f\"\\n‚öôÔ∏è Next Steps:\")\n","print(\"=\"*70)\n","print(\"1. ‚úÖ Review the 'matched' folder - Are these correct?\")\n","print(\"2. ‚úÖ Review the 'review' folder - Manually classify these\")\n","print(\"3. ‚úÖ Check 'not_matched' - Any photos of you missed?\")\n","print(\"\\n4. If results are GOOD:\")\n","print(\"   ‚Üí You're ready to process your full 5K collection!\")\n","print(\"\\n5. If results need improvement:\")\n","print(\"   ‚Üí Adjust tolerance value (try 0.5 for stricter or 0.7 for lenient)\")\n","print(\"   ‚Üí Add more reference photos\")\n","print(\"   ‚Üí Run processing again\")\n","print(\"=\"*70)"],"metadata":{"id":"jqMgFu_Hnvi9"},"execution_count":null,"outputs":[]}]}